{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "06I9y-CtwyR_"
      },
      "outputs": [],
      "source": [
        "import zipfile\n",
        "\n",
        "# Importing the tarfile module for working with tar files\n",
        "import tarfile\n",
        "# Importing all neccessary modeules\n",
        "import spacy\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "import sys\n",
        "import re\n",
        "import joblib\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UNdQt4WR0wbw"
      },
      "outputs": [],
      "source": [
        " # Mount google drive if google colab is being used\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qmYRD0r_0xnO"
      },
      "outputs": [],
      "source": [
        "file_path = '/content/spam.csv'\n",
        "try:\n",
        "    emails_df = pd.read_csv(file_path, encoding='utf-8')\n",
        "except UnicodeDecodeError:\n",
        "    try:\n",
        "        emails_df = pd.read_csv(file_path, encoding='latin1')\n",
        "    except UnicodeDecodeError:\n",
        "        try:\n",
        "            emails_df = pd.read_csv(file_path, encoding='ISO-8859-1')\n",
        "        except UnicodeDecodeError:\n",
        "            emails_df = pd.read_csv(file_path, encoding='cp1252')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ezxaKyup06wH"
      },
      "outputs": [],
      "source": [
        "# Set base folder and append custome module paths\n",
        "if 'google.colab' in str(get_ipython()):\n",
        "  !pip install -U nltk -qq\n",
        "  !pip install -U spacy -qq\n",
        "  !python -m spacy download en_core_web_sm -qq\n",
        "  base_folder = Path('/content/drive/MyDrive/base_folder')\n",
        "  sys.path.append('/content/drive/MyDrive/custom_functions')\n",
        "else:\n",
        "    base_folder = Path('/content/drive/MyDrive/base_folder')\n",
        "    sys.path.append('/content/drive/MyDrive/custom_functions')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SwtW5WjA5Bs3"
      },
      "outputs": [],
      "source": [
        "data_folder = base_folder/'datasets'\n",
        "archive_folder = base_folder/'archive'\n",
        "model_folder = base_folder/'models'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "auUBXlkL8Eqm"
      },
      "outputs": [],
      "source": [
        "# Download spacy model\n",
        "if 'google.colab' in str(get_ipython()):\n",
        "    !python -m spacy download en_core_web_sm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "svuYkKkT0Aky"
      },
      "outputs": [],
      "source": [
        "# Read csv file into a dataframe\n",
        "df = pd.read_csv('spam.csv', encoding=\"ISO-8859-1\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4eOWhLF_0q2i"
      },
      "outputs": [],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ytPBmaT1DRx4"
      },
      "outputs": [],
      "source": [
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bNEEwnPeEV2j"
      },
      "outputs": [],
      "source": [
        "# Install and import the swifter module\n",
        "!pip install swifter\n",
        "import swifter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iZWsg1kuEaPi"
      },
      "outputs": [],
      "source": [
        "# Renaming the main columns needed and dropping unused columns\n",
        "df.rename(columns={'v1': 'label', 'v2': 'message'}, inplace = True)\n",
        "df = df.drop(labels=[\"Unnamed: 2\", \"Unnamed: 3\", \"Unnamed: 4\"], axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fK1Wz1ApS0yO"
      },
      "outputs": [],
      "source": [
        "# Get the percentage of spam observations to the percentage of ham\n",
        "perc_of_spam = sum(df['label'].swifter.apply(lambda x: 1 if x == \"spam\" else 0))/len(df) * 100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hCtmlRuNTEIQ"
      },
      "outputs": [],
      "source": [
        "print(\"The percentage of spam in the dataset is\", perc_of_spam, \"While the percentage of ham is\", 100 - perc_of_spam)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0DKd1D4RVChI"
      },
      "outputs": [],
      "source": [
        "# Import required nltk packages\n",
        "import nltk\n",
        "nltk.download('stopwords')  # Download the stopwords corpus\n",
        "from nltk.corpus import stopwords as nltk_stopwords  # Stopwords corpus\n",
        "\n",
        "# Import tweet tokenizer from nltk\n",
        "from nltk.tokenize import TweetTokenizer\n",
        "\n",
        "# Import CountVectorizer and TfidfVectorizer from scikit-learn\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NUSGEirfVL6u"
      },
      "outputs": [],
      "source": [
        "# Import the joblib library for saving and loading models\n",
        "import joblib\n",
        "\n",
        "# Import scikit-learn classes for building models\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.base import TransformerMixin, BaseEstimator\n",
        "\n",
        "# Import the scipy library for working with sparse matrices\n",
        "from scipy.sparse import csr_matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6Iafu-ZTVPub"
      },
      "outputs": [],
      "source": [
        "import custom_preprocessor_mod as cp\n",
        "from  featurizer import ManualFeatures\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9BqTxpW0bqwV"
      },
      "outputs": [],
      "source": [
        "# Change the label column into ones and zeroes (1 for spam email and 0 for non-spam)\n",
        "df['label'] = df['label'].swifter.apply(lambda x: 1 if x==\"spam\" else 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1DyzbcJkbwlA"
      },
      "outputs": [],
      "source": [
        "len(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9isTYWeIbzXo"
      },
      "outputs": [],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OzmT-4xEgzSI"
      },
      "outputs": [],
      "source": [
        "df_cleaned = cp.SpacyPreprocessor(model = \"en_core_web_sm\").transform(df['message'].values)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XC4dJrx6gzOO"
      },
      "outputs": [],
      "source": [
        "# save this to a file\n",
        "file_df_cleaned_sparse_embed = data_folder / 'df_cleaned_sparse_embed.pkl'\n",
        "joblib.dump(df_cleaned, file_df_cleaned_sparse_embed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LduN5Gm9gzLM"
      },
      "outputs": [],
      "source": [
        "cleaned_text_df = joblib.load(file_df_cleaned_sparse_embed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mWZwzm8_iHR0"
      },
      "outputs": [],
      "source": [
        "# Create an instance of the ManualFeatures class\n",
        "featurizer = ManualFeatures(spacy_model='en_core_web_sm')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "esdxk_ldgzH_"
      },
      "outputs": [],
      "source": [
        "# Transform the X_train data into manual features\n",
        "X_features_values, feature_names = featurizer.fit_transform(cleaned_text_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0196MjJxiM21"
      },
      "outputs": [],
      "source": [
        "# Convert the numpy array into a dataframe\n",
        "spam_df = pd.DataFrame(X_features_values, columns = feature_names)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6Zip7F-PigFC"
      },
      "outputs": [],
      "source": [
        "spam_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-OXMrdEMif4e"
      },
      "outputs": [],
      "source": [
        "# Download pyspellchecker\n",
        "! pip install pyspellchecker"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hYywX8v6gzDo"
      },
      "outputs": [],
      "source": [
        "from spellchecker import SpellChecker\n",
        "\n",
        "spell = SpellChecker()\n",
        "\n",
        "def check_spelling(sentence):\n",
        "  misspelled = spell.unknown(re.findall(r\"[\\w']+|[.,!?;]\", sentence))\n",
        "  return len(misspelled)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H9gynWcPixtY"
      },
      "outputs": [],
      "source": [
        "# Convert the numpy array of text into a dataframe\n",
        "spam_text = pd.DataFrame(cleaned_text_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sIviGXQ2jY8y"
      },
      "outputs": [],
      "source": [
        "spam_text.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8t7HLFNTixmt"
      },
      "outputs": [],
      "source": [
        "# Include an additional column in the train data that shows the number of mistakes in the sentence\n",
        "spam_df['no_of_spelling_mistakes'] = spam_text[0].swifter.apply(lambda x: check_spelling(x))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DekzmBkPixgH"
      },
      "outputs": [],
      "source": [
        "spam_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ImNCKBP8gy_g"
      },
      "outputs": [],
      "source": [
        "spam_df_combined = pd.concat((pd.DataFrame(spam_text),\n",
        "                              pd.DataFrame(spam_df)), axis = 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vHuqYFGSjvap"
      },
      "outputs": [],
      "source": [
        "spam_df_combined\n",
        "###This is the combined dataset now"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "lGR5uqFkWyca"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spam_df_combined2 = pd.concat((pd.DataFrame(df),\n",
        "                              pd.DataFrame(spam_df_combined)), axis = 1)"
      ],
      "metadata": {
        "id": "rRkelcxxYH5G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spam_df_combined2.head()"
      ],
      "metadata": {
        "id": "VQnD_6QUY1mj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Drop the 'message' column\n",
        "spam_df_combined2 = spam_df_combined2.drop('message', axis=1)\n",
        "\n",
        "# Rename the '0' column to 'message'\n",
        "spam_df_combined2 = spam_df_combined2.rename(columns={0: 'message'})\n"
      ],
      "metadata": {
        "id": "iGFs5oP9bfS8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spam_df_combined2.head()"
      ],
      "metadata": {
        "id": "F4akM1xBbhly"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spam_df_combined2.to_csv('spam_df_combined_with_labels.csv', index=False)\n"
      ],
      "metadata": {
        "id": "xzNVbekiboHf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download('spam_df_combined_with_labels.csv')\n"
      ],
      "metadata": {
        "id": "x10l6wzYb4UM"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}