{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "06I9y-CtwyR_"
      },
      "outputs": [],
      "source": [
        "import zipfile\n",
        "\n",
        "# Importing the tarfile module for working with tar files\n",
        "import tarfile\n",
        "# Importing all neccessary modeules\n",
        "import spacy\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "import sys\n",
        "import re\n",
        "import joblib\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 329
        },
        "id": "UNdQt4WR0wbw",
        "outputId": "100ae900-f55b-4175-f85c-7c044eba95a0"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "MessageError",
          "evalue": "Error: credential propagation was unsuccessful",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mMessageError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-46ada51c1d10>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Mount google drive if google colab is being used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, readonly)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m120000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreadonly\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m   \u001b[0;34m\"\"\"Mount your Google Drive at the specified mountpoint path.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m   return _mount(\n\u001b[0m\u001b[1;32m    101\u001b[0m       \u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m       \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_remount\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36m_mount\u001b[0;34m(mountpoint, force_remount, timeout_ms, ephemeral, readonly)\u001b[0m\n\u001b[1;32m    131\u001b[0m   )\n\u001b[1;32m    132\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mephemeral\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 133\u001b[0;31m     _message.blocking_request(\n\u001b[0m\u001b[1;32m    134\u001b[0m         \u001b[0;34m'request_auth'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'authType'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'dfs_ephemeral'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m     )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mblocking_request\u001b[0;34m(request_type, request, timeout_sec, parent)\u001b[0m\n\u001b[1;32m    174\u001b[0m       \u001b[0mrequest_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpect_reply\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m   )\n\u001b[0;32m--> 176\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m    101\u001b[0m     ):\n\u001b[1;32m    102\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;34m'error'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mMessageError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'error'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mMessageError\u001b[0m: Error: credential propagation was unsuccessful"
          ]
        }
      ],
      "source": [
        " # Mount google drive if google colab is being used\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qmYRD0r_0xnO"
      },
      "outputs": [],
      "source": [
        "file_path = '/content/spam.csv'\n",
        "try:\n",
        "    emails_df = pd.read_csv(file_path, encoding='utf-8')\n",
        "except UnicodeDecodeError:\n",
        "    try:\n",
        "        emails_df = pd.read_csv(file_path, encoding='latin1')\n",
        "    except UnicodeDecodeError:\n",
        "        try:\n",
        "            emails_df = pd.read_csv(file_path, encoding='ISO-8859-1')\n",
        "        except UnicodeDecodeError:\n",
        "            emails_df = pd.read_csv(file_path, encoding='cp1252')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ezxaKyup06wH"
      },
      "outputs": [],
      "source": [
        "# Set base folder and append custome module paths\n",
        "if 'google.colab' in str(get_ipython()):\n",
        "  !pip install -U nltk -qq\n",
        "  !pip install -U spacy -qq\n",
        "  !python -m spacy download en_core_web_sm -qq\n",
        "  base_folder = Path('/content/drive/MyDrive/base_folder')\n",
        "  sys.path.append('/content/drive/Othercomputers/Samsung_Laptop/School/Spring_2023_Semester/BUAN_6342_Applied_Natural_Language_Processing/Custom_Functions_py_files')\n",
        "else:\n",
        "    base_folder = Path('/content/drive/MyDrive/base_folder')\n",
        "    sys.path.append('/Users/12544/Desktop/School/Spring_2023_Semester/BUAN_6342_Applied_Natural_Language_Processing/Custom_Functions_py_files')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SwtW5WjA5Bs3"
      },
      "outputs": [],
      "source": [
        "data_folder = base_folder/'datasets'\n",
        "archive_folder = base_folder/'archive'\n",
        "model_folder = base_folder/'models'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "auUBXlkL8Eqm"
      },
      "outputs": [],
      "source": [
        "# Download spacy model\n",
        "if 'google.colab' in str(get_ipython()):\n",
        "    !python -m spacy download en_core_web_sm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "svuYkKkT0Aky"
      },
      "outputs": [],
      "source": [
        "# Read csv file into a dataframe\n",
        "df = pd.read_csv('spam.csv', encoding=\"ISO-8859-1\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4eOWhLF_0q2i"
      },
      "outputs": [],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ytPBmaT1DRx4"
      },
      "outputs": [],
      "source": [
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bNEEwnPeEV2j"
      },
      "outputs": [],
      "source": [
        "# Install and import the swifter module\n",
        "!pip install swifter\n",
        "import swifter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iZWsg1kuEaPi"
      },
      "outputs": [],
      "source": [
        "# Renaming the main columns needed and dropping unused columns\n",
        "df.rename(columns={'v1': 'label', 'v2': 'message'}, inplace = True)\n",
        "df = df.drop(labels=[\"Unnamed: 2\", \"Unnamed: 3\", \"Unnamed: 4\"], axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fK1Wz1ApS0yO"
      },
      "outputs": [],
      "source": [
        "# Get the percentage of spam observations to the percentage of ham\n",
        "perc_of_spam = sum(df['label'].swifter.apply(lambda x: 1 if x == \"spam\" else 0))/len(df) * 100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hCtmlRuNTEIQ"
      },
      "outputs": [],
      "source": [
        "print(\"The percentage of spam in the dataset is\", perc_of_spam, \"While the percentage of ham is\", 100 - perc_of_spam)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0DKd1D4RVChI"
      },
      "outputs": [],
      "source": [
        "# Import required nltk packages\n",
        "import nltk\n",
        "nltk.download('stopwords')  # Download the stopwords corpus\n",
        "from nltk.corpus import stopwords as nltk_stopwords  # Stopwords corpus\n",
        "\n",
        "# Import tweet tokenizer from nltk\n",
        "from nltk.tokenize import TweetTokenizer\n",
        "\n",
        "# Import CountVectorizer and TfidfVectorizer from scikit-learn\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NUSGEirfVL6u"
      },
      "outputs": [],
      "source": [
        "# Import the joblib library for saving and loading models\n",
        "import joblib\n",
        "\n",
        "# Import scikit-learn classes for building models\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.base import TransformerMixin, BaseEstimator\n",
        "\n",
        "# Import the scipy library for working with sparse matrices\n",
        "from scipy.sparse import csr_matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6Iafu-ZTVPub"
      },
      "outputs": [],
      "source": [
        "import custom_preprocessor_mod as cp\n",
        "from  featurizer import ManualFeatures\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9BqTxpW0bqwV"
      },
      "outputs": [],
      "source": [
        "# Change the label column into ones and zeroes (1 for spam email and 0 for non-spam)\n",
        "df['label'] = df['label'].swifter.apply(lambda x: 1 if x==\"spam\" else 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1DyzbcJkbwlA"
      },
      "outputs": [],
      "source": [
        "len(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9isTYWeIbzXo"
      },
      "outputs": [],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OzmT-4xEgzSI"
      },
      "outputs": [],
      "source": [
        "df_cleaned = cp.SpacyPreprocessor(model = \"en_core_web_sm\").transform(df['message'].values)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XC4dJrx6gzOO"
      },
      "outputs": [],
      "source": [
        "# save this to a file\n",
        "file_df_cleaned_sparse_embed = data_folder / 'df_cleaned_sparse_embed.pkl'\n",
        "joblib.dump(df_cleaned, file_df_cleaned_sparse_embed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LduN5Gm9gzLM"
      },
      "outputs": [],
      "source": [
        "cleaned_text_df = joblib.load(file_df_cleaned_sparse_embed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mWZwzm8_iHR0"
      },
      "outputs": [],
      "source": [
        "# Create an instance of the ManualFeatures class\n",
        "featurizer = ManualFeatures(spacy_model='en_core_web_sm')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "esdxk_ldgzH_"
      },
      "outputs": [],
      "source": [
        "# Transform the X_train data into manual features\n",
        "X_features_values, feature_names = featurizer.fit_transform(cleaned_text_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0196MjJxiM21"
      },
      "outputs": [],
      "source": [
        "# Convert the numpy array into a dataframe\n",
        "spam_df = pd.DataFrame(X_features_values, columns = feature_names)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6Zip7F-PigFC"
      },
      "outputs": [],
      "source": [
        "spam_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-OXMrdEMif4e"
      },
      "outputs": [],
      "source": [
        "# Download pyspellchecker\n",
        "! pip install pyspellchecker"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hYywX8v6gzDo"
      },
      "outputs": [],
      "source": [
        "from spellchecker import SpellChecker\n",
        "\n",
        "spell = SpellChecker()\n",
        "\n",
        "def check_spelling(sentence):\n",
        "  misspelled = spell.unknown(re.findall(r\"[\\w']+|[.,!?;]\", sentence))\n",
        "  return len(misspelled)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H9gynWcPixtY"
      },
      "outputs": [],
      "source": [
        "# Convert the numpy array of text into a dataframe\n",
        "spam_text = pd.DataFrame(cleaned_text_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sIviGXQ2jY8y"
      },
      "outputs": [],
      "source": [
        "spam_text.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8t7HLFNTixmt"
      },
      "outputs": [],
      "source": [
        "# Include an additional column in the train data that shows the number of mistakes in the sentence\n",
        "spam_df['no_of_spelling_mistakes'] = spam_text[0].swifter.apply(lambda x: check_spelling(x))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DekzmBkPixgH"
      },
      "outputs": [],
      "source": [
        "spam_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ImNCKBP8gy_g"
      },
      "outputs": [],
      "source": [
        "spam_df_combined = pd.concat((pd.DataFrame(spam_text),\n",
        "                              pd.DataFrame(spam_df)), axis = 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vHuqYFGSjvap"
      },
      "outputs": [],
      "source": [
        "spam_df_combined\n",
        "###This is the combined dataset now"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}